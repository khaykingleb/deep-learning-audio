_target_: src.collections.audio.asr.data.ASRData

batch_size: 16  # needs to be divisible by the number of devices (e.g., if in a distributed setup)
num_workers: 8
persistent_workers: true
pin_memory: false
downsize: 2

dataset:
  _target_: src.collections.audio.asr.datasets.LJSpeechDataset
  data_dir: data/
  data_proportions: [0.75, 0.2, 0.05]  # TODO(khaykingleb): make train/val/test
  tokenizer:
    _target_: src.collections.common.preprocessing.tokenizers.CTCTextTokenizer
    blank_symbol: "Ïµ"
    alphabet: [
      "a", "b", "c", "d", "e", "f", "g", "h", "i", "j", "k", "l", "m", "n",
      "o", "p", "q", "r", "s", "t", "u", "v", "w", "x", "y", "z", " ",
    ]

  augmenter:
    _target_: src.collections.audio.dsp.augmentation.AudioAugmenter
    sample_rate: 16_000
    use_sox_effects: true
    use_room_reverberation: true
    use_background_noise: true
    max_pitch_shift: 10
    max_tempo_change: 0.3
    snr_dbs: [20, 15, 10]

  transformer:
    _target_: torchaudio.transforms.MelSpectrogram
    sample_rate: 16_000
    n_mels: 64 # mumber of mel filterbanks
    mel_scale: htk  # mel = 2595.0 * np.log10(1.0 + f / 700.0)

  text_max_length: 100
  audio_max_duration: 10.0
  audio_sample_rate: 22050
  audio_aug_prob: 0.3
